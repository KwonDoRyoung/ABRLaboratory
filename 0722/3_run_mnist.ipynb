{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KwonDoRyoung/ABRLaboratory/blob/main/0722/3_run_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk7VVgFxmFPw"
      },
      "source": [
        "# Import modules"
      ],
      "id": "fk7VVgFxmFPw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTbk4yfgmFPx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "import torchvision.datasets as datasets\n",
        "import torch.cuda as cuda\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "id": "hTbk4yfgmFPx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdrZ4uDZmFPy"
      },
      "source": [
        "# Define MLP network"
      ],
      "id": "kdrZ4uDZmFPy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJ3dkrCCmFPy"
      },
      "outputs": [],
      "source": [
        "# define MLP network with one hidden layer (original version)\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.flatten = nn.Flatten() # flatten the input tensor as a 1D vector ((28, 28) -> (784))\n",
        "        self.input_layer = nn.Linear(28*28, 512)\n",
        "        self.hidden_layer = nn.Linear(512, 256)\n",
        "        self.output_layer = nn.Linear(256, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        h = self.relu(self.input_layer(x))\n",
        "        h = self.relu(self.hidden_layer(h))\n",
        "        y = self.output_layer(h)\n",
        "        return y"
      ],
      "id": "VJ3dkrCCmFPy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxQrHZ_3mFPz"
      },
      "source": [
        "# Define run_mnist function"
      ],
      "id": "wxQrHZ_3mFPz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIdTpd4TmFPz"
      },
      "outputs": [],
      "source": [
        "def run_mnist(\n",
        "    training=True,\n",
        "    save_path='model.pt',\n",
        "    epochs=10,\n",
        "    random_seed=0xAB,\n",
        "    valid_ratio=0.1\n",
        "):\n",
        "    \n",
        "    device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "    myMLP = MLP().to(device)\n",
        "    \n",
        "    # train mode\n",
        "    if training:\n",
        "        \n",
        "        # load checkpoint:\n",
        "        if os.path.exists(save_path):\n",
        "            myMLP.load_state_dict(torch.load(save_path))\n",
        "        \n",
        "        # load or download MNIST datasets\n",
        "        train_data = datasets.MNIST(root='./data', train=True, download=True, transform=T.ToTensor())\n",
        "        valid_data = datasets.MNIST(root='./data', train=True, download=True, transform=T.ToTensor())\n",
        "        \n",
        "        # fix random seed\n",
        "        np.random.seed(random_seed)\n",
        "        torch.manual_seed(random_seed)\n",
        "        \n",
        "        # split given train data into train and valid dataset\n",
        "        num_train = len(train_data)\n",
        "        indices = list(range(num_train))\n",
        "        num_valid = int(valid_ratio * num_train)\n",
        "        \n",
        "        train_idx, valid_idx = indices[num_valid:], indices[:num_valid]\n",
        "\n",
        "        train_sampler = SubsetRandomSampler(train_idx)\n",
        "        valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "        \n",
        "        # create data loaders to feed data into our model\n",
        "        batch_size = 64\n",
        "        train_dataloader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\n",
        "        valid_dataloader = DataLoader(valid_data, batch_size=batch_size, sampler=valid_sampler)\n",
        "        \n",
        "        # define a loss function and an optimizer\n",
        "        loss_fn = nn.CrossEntropyLoss(reduction='mean')\n",
        "        optimizer = torch.optim.SGD(myMLP.parameters(), lr=5e-3)\n",
        "        \n",
        "        report_interval = 100\n",
        "        max_valid_acc = 0\n",
        "        \n",
        "        ndata = len(train_dataloader.dataset)\n",
        "        print('training starts!')\n",
        "\n",
        "        for e in range(epochs):\n",
        "            print(f'\\nepoch {e+1}\\n------------------------------')\n",
        "            myMLP.train() # train mode\n",
        "\n",
        "            for b, (X, y) in enumerate(train_dataloader):\n",
        "                X, y = X.to(device), y.to(device) # input and target to device(gpu)\n",
        "\n",
        "                prediction = myMLP(X) # forward pass\n",
        "                train_loss = loss_fn(prediction, y) # calculate the loss \n",
        "\n",
        "                optimizer.zero_grad() # clear gradients\n",
        "                train_loss.backward() # backpropagation\n",
        "                optimizer.step() # update the parameters\n",
        "\n",
        "                if b % report_interval == 0: # track the training\n",
        "                    train_loss, current = train_loss.item(), b * len(X) \n",
        "                    print(f'[{current:>5d}/{ndata:>5d}]  train loss: {train_loss:>7f}  ', end=\"\")\n",
        "\n",
        "                    myMLP.eval()\n",
        "                    with torch.no_grad():\n",
        "                        valid_ndata = 0\n",
        "                        valid_nbatch = len(valid_dataloader)\n",
        "                        valid_loss, valid_correct = 0, 0\n",
        "                        for X, y in valid_dataloader:\n",
        "                            X, y = X.to(device), y.to(device)\n",
        "                            prediction = myMLP(X)\n",
        "                            valid_loss += loss_fn(prediction, y).item() # add up the loss\n",
        "                            valid_correct += (prediction.argmax(1) == y).type(torch.float).sum().item() # add up the correct predictions\n",
        "                            valid_ndata += len(X)\n",
        "                        valid_loss /= valid_nbatch\n",
        "                        valid_correct /= valid_ndata\n",
        "                        print(f\"valid accuracy: {(100*valid_correct):>0.1f}%, valid loss: {valid_loss:>8f}\")\n",
        "\n",
        "                    if max_valid_acc < valid_correct:\n",
        "                        torch.save(myMLP.state_dict(), save_path)\n",
        "                        max_valid_acc = valid_correct\n",
        "\n",
        "        print('\\ntraining is finished!')\n",
        "    \n",
        "    # evaluation mode\n",
        "    else:\n",
        "        \n",
        "        if os.path.exists(save_path):\n",
        "            myMLP.load_state_dict(torch.load(save_path))\n",
        "        else:\n",
        "            print(f'There is no checkpoint filename {save_path}')\n",
        "            sys.exit()\n",
        "        \n",
        "        # load or download MNIST datasets\n",
        "        test_data = datasets.MNIST(root='./data', train=False, download=True, transform=T.ToTensor())\n",
        "        \n",
        "        # create data loaders to feed data into our model\n",
        "        batch_size = 64\n",
        "        test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "        \n",
        "        # test the MLP model\n",
        "        ndata = len(test_dataloader.dataset)\n",
        "        nbatch = len(test_dataloader)\n",
        "        myMLP.eval() # test mode\n",
        "        correct = 0 # initialize\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for X, y in test_dataloader:\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                prediction = myMLP(X)\n",
        "                correct += (prediction.argmax(1) == y).type(torch.float).sum().item() # add up the correct predictions\n",
        "        correct /= ndata # accuracy for all data\n",
        "        print(f\"Test accuracy: {(100*correct):>0.1f}%\")"
      ],
      "id": "sIdTpd4TmFPz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlTFgmEpmFP0"
      },
      "source": [
        "# Training"
      ],
      "id": "hlTFgmEpmFP0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DULU5ItEmFP0",
        "outputId": "f83613ea-c215-4ba6-9967-e27c75941090"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training starts!\n",
            "\n",
            "epoch 1\n",
            "------------------------------\n",
            "[    0/60000]  train loss: 2.301766  valid accuracy: 12.1%, valid loss: 2.301702\n",
            "[ 6400/60000]  train loss: 2.286403  valid accuracy: 29.4%, valid loss: 2.281255\n",
            "[12800/60000]  train loss: 2.252296  valid accuracy: 43.5%, valid loss: 2.258803\n",
            "[19200/60000]  train loss: 2.221064  valid accuracy: 52.7%, valid loss: 2.231353\n",
            "[25600/60000]  train loss: 2.196161  valid accuracy: 60.3%, valid loss: 2.196320\n",
            "[32000/60000]  train loss: 2.176315  valid accuracy: 62.7%, valid loss: 2.149452\n",
            "[38400/60000]  train loss: 2.094090  valid accuracy: 64.8%, valid loss: 2.087826\n",
            "[44800/60000]  train loss: 2.024556  valid accuracy: 67.4%, valid loss: 2.002415\n",
            "[51200/60000]  train loss: 1.911689  valid accuracy: 68.6%, valid loss: 1.893471\n",
            "\n",
            "training is finished!\n"
          ]
        }
      ],
      "source": [
        "run_mnist(\n",
        "    training=True,\n",
        "    save_path='model.pt',\n",
        "    epochs=1,\n",
        "    random_seed=0xAB,\n",
        "    valid_ratio=0.1\n",
        ")"
      ],
      "id": "DULU5ItEmFP0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fL4uwIlEmFP1",
        "outputId": "d5e5f6fb-9ddf-441f-b9a0-35408ca9aa41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training starts!\n",
            "\n",
            "epoch 1\n",
            "------------------------------\n",
            "[    0/60000]  train loss: 2.304593  valid accuracy: 9.9%, valid loss: 2.304173\n",
            "[ 6400/60000]  train loss: 2.281907  valid accuracy: 24.6%, valid loss: 2.282630\n",
            "[12800/60000]  train loss: 2.259383  valid accuracy: 46.2%, valid loss: 2.259212\n",
            "[19200/60000]  train loss: 2.237567  valid accuracy: 55.7%, valid loss: 2.230620\n",
            "[25600/60000]  train loss: 2.208418  valid accuracy: 61.5%, valid loss: 2.195406\n",
            "[32000/60000]  train loss: 2.166166  valid accuracy: 66.3%, valid loss: 2.148903\n",
            "[38400/60000]  train loss: 2.081265  valid accuracy: 67.2%, valid loss: 2.084625\n",
            "[44800/60000]  train loss: 1.993808  valid accuracy: 68.5%, valid loss: 1.998226\n",
            "[51200/60000]  train loss: 1.961805  valid accuracy: 71.0%, valid loss: 1.885194\n",
            "\n",
            "training is finished!\n",
            "training starts!\n",
            "\n",
            "epoch 1\n",
            "------------------------------\n",
            "[    0/60000]  train loss: 2.303794  valid accuracy: 8.2%, valid loss: 2.307722\n",
            "[ 6400/60000]  train loss: 2.286244  valid accuracy: 12.1%, valid loss: 2.287078\n",
            "[12800/60000]  train loss: 2.251655  valid accuracy: 18.0%, valid loss: 2.264135\n",
            "[19200/60000]  train loss: 2.240515  valid accuracy: 36.6%, valid loss: 2.235936\n",
            "[25600/60000]  train loss: 2.208672  valid accuracy: 50.6%, valid loss: 2.199336\n",
            "[32000/60000]  train loss: 2.130199  valid accuracy: 57.6%, valid loss: 2.151545\n",
            "[38400/60000]  train loss: 2.106770  valid accuracy: 67.2%, valid loss: 2.088876\n",
            "[44800/60000]  train loss: 2.021533  valid accuracy: 71.0%, valid loss: 2.007486\n",
            "[51200/60000]  train loss: 1.975473  valid accuracy: 72.6%, valid loss: 1.902944\n",
            "\n",
            "training is finished!\n"
          ]
        }
      ],
      "source": [
        "for i in range(2):\n",
        "    run_mnist(\n",
        "        training=True,\n",
        "        save_path='model{}.pt'.format(i),\n",
        "        epochs=1,\n",
        "        random_seed=i,\n",
        "        valid_ratio=0.1\n",
        "    )"
      ],
      "id": "fL4uwIlEmFP1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diQFKB2nmFP1"
      },
      "source": [
        "# Evaluation"
      ],
      "id": "diQFKB2nmFP1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgXAAuHKmFP1",
        "outputId": "b417e61a-0589-4d67-ffa1-b3172d8d9ed5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 67.7%\n"
          ]
        }
      ],
      "source": [
        "run_mnist(\n",
        "    training=False,\n",
        "    save_path='model.pt'\n",
        ")"
      ],
      "id": "IgXAAuHKmFP1"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "vaca",
      "language": "python",
      "name": "vaca"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "name": "3-run_mnist.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}