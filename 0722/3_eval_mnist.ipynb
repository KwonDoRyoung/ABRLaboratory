{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KwonDoRyoung/ABRLaboratory/blob/main/0722/3_eval_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txecQwIAmOj0"
      },
      "outputs": [],
      "source": [
        "# import transforms and datasets in TorchVision\n",
        "import torchvision.transforms as T\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "# load or download MNIST datasets\n",
        "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=T.ToTensor())"
      ],
      "id": "txecQwIAmOj0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iM4LCb6NmOj1"
      },
      "outputs": [],
      "source": [
        "# import DataLoader in PyTorch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# create data loaders to feed data into our model\n",
        "batch_size = 64\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
      ],
      "id": "iM4LCb6NmOj1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ic1M_I7smOj2"
      },
      "outputs": [],
      "source": [
        "# import nn in PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# define MLP network with one hidden layer (original version)\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.flatten = nn.Flatten() # flatten the input tensor as a 1D vector ((28, 28) -> (784))\n",
        "        self.input_layer = nn.Linear(28*28, 512)\n",
        "        self.hidden_layer = nn.Linear(512, 256)\n",
        "        self.output_layer = nn.Linear(256, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        h = self.relu(self.input_layer(x))\n",
        "        h = self.relu(self.hidden_layer(h))\n",
        "        y = self.output_layer(h)\n",
        "        return y"
      ],
      "id": "ic1M_I7smOj2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "D-H-ceJJmOj2"
      },
      "outputs": [],
      "source": [
        "# import cuda in PyTorch\n",
        "import torch.cuda as cuda\n",
        "\n",
        "# check device for training\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "\n",
        "# get the MLP model and send it to the device\n",
        "myMLP = MLP().to(device)"
      ],
      "id": "D-H-ceJJmOj2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EIlv0dKmOj3"
      },
      "outputs": [],
      "source": [
        "# load trained weight\n",
        "import os\n",
        "import sys\n",
        "\n",
        "save_path = 'model.pt'\n",
        "\n",
        "if os.path.exists(save_path):\n",
        "    myMLP.load_state_dict(torch.load(save_path))\n",
        "else:\n",
        "    print(f'There is no checkpoint filename {save_path}')\n",
        "    sys.exit()"
      ],
      "id": "6EIlv0dKmOj3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXA_mQY0mOj3",
        "outputId": "e3b24150-07e1-4955-8096-5ceb11bf10f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 89.6%\n"
          ]
        }
      ],
      "source": [
        "# test the MLP model\n",
        "ndata = len(test_dataloader.dataset)\n",
        "nbatch = len(test_dataloader)\n",
        "myMLP.eval() # test mode\n",
        "correct = 0 # initialize\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X, y in test_dataloader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        prediction = myMLP(X)\n",
        "        correct += (prediction.argmax(1) == y).type(torch.float).sum().item() # add up the correct predictions\n",
        "correct /= ndata # accuracy for all data\n",
        "print(f\"Test accuracy: {(100*correct):>0.1f}%\")"
      ],
      "id": "mXA_mQY0mOj3"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "vaca",
      "language": "python",
      "name": "vaca"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "name": "3-eval_mnist.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}